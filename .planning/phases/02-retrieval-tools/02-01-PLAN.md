---
phase: 02-retrieval-tools
plan: "01"
type: execute
wave: 1
depends_on: []
files_modified:
  - execution/vector_db/metadata_filters.py
  - execution/vector_db/recency_scoring.py
  - execution/vector_db/citations.py
autonomous: true

must_haves:
  truths:
    - "Metadata filters scope vector search by date range, source type, and topic tags at the SQL layer"
    - "Recency scoring applies exponential half-life decay to prioritize recent documents for trend queries"
    - "Citation extractor splits chunks into sentences with unique citation IDs and markdown links"
  artifacts:
    - path: "execution/vector_db/metadata_filters.py"
      provides: "SQLAlchemy filter builders for scoped retrieval"
      exports: ["MetadataFilter", "build_filters"]
    - path: "execution/vector_db/recency_scoring.py"
      provides: "Time decay functions for recency-aware ranking"
      exports: ["RecencyScorer"]
    - path: "execution/vector_db/citations.py"
      provides: "Sentence-level citation extraction with pysbd"
      exports: ["CitationExtractor", "Citation"]
  key_links:
    - from: "execution/vector_db/metadata_filters.py"
      to: "execution/vector_db/models.py"
      via: "SQLAlchemy column references"
      pattern: "KnowledgeChunk\\.topic_tags|Document\\.date_published|Document\\.source_type"
    - from: "execution/vector_db/citations.py"
      to: "pysbd"
      via: "Sentence segmentation"
      pattern: "pysbd\\.Segmenter"
---

<objective>
Build three independent utility modules that the hybrid retrieval orchestrator (Plan 02-03) will compose together: metadata filtering, recency scoring, and citation extraction.

Purpose: These are the building blocks that transform raw vector search into production-quality RAG retrieval. Metadata filters ensure searches are scoped efficiently at the SQL layer. Recency scoring prevents stale results for trend queries. Citations enable sentence-level source attribution in generated content.

Output: Three new Python modules in execution/vector_db/ — each self-contained, importable, and testable independently.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-retrieval-tools/02-RESEARCH.md

# Existing code this plan builds on
@execution/vector_db/models.py
@execution/vector_db/connection.py
@execution/vector_db/chunking.py
@execution/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Metadata Filter Builders</name>
  <files>execution/vector_db/metadata_filters.py</files>
  <action>
Create `execution/vector_db/metadata_filters.py` with a `MetadataFilter` class providing static filter builder methods and a `build_filters()` convenience function.

**MetadataFilter class with static methods:**

1. `date_range(start_date: datetime, end_date: datetime)` — Returns SQLAlchemy `and_()` condition on `Document.date_published >= start_date` AND `Document.date_published <= end_date`. Handle None start/end (open-ended ranges).

2. `source_types(types: List[str])` — Returns `Document.source_type.in_(types)` condition. Validate types is non-empty list.

3. `topic_tags(tags: List[str], match_any: bool = True)` — For `match_any=True`, returns `or_()` of `KnowledgeChunk.topic_tags.contains([tag])` for each tag. For `match_any=False`, returns `KnowledgeChunk.topic_tags.contains(tags)` (all tags must be present). Uses SQLAlchemy JSONB `contains` operator.

4. `recency(months: int = 6)` — Shorthand for `Document.date_published >= (utcnow - months*30 days)`.

5. `entities(entity_values: List[str], match_any: bool = True)` — Filter by entity values in the JSONB `entities` column. Similar to topic_tags but searches `entities` array of `{type, value}` objects. Use raw SQL `jsonb_path_exists` or JSONB `@>` operator for nested matching.

**`build_filters()` function:**
```python
def build_filters(
    tenant_id: str,
    date_range: Optional[Tuple[datetime, datetime]] = None,
    source_types: Optional[List[str]] = None,
    topic_tags: Optional[List[str]] = None,
    topic_match_any: bool = True,
    recency_months: Optional[int] = None,
) -> List:
```
Accepts a dict-like set of filter params and returns a list of SQLAlchemy conditions that can be passed to `.where(*conditions)`. Always includes `KnowledgeChunk.tenant_id == tenant_id` and `KnowledgeChunk.embedding.isnot(None)`.

**Important patterns:**
- Import models: `from execution.vector_db.models import KnowledgeChunk, Document`
- Import SQLAlchemy: `from sqlalchemy import and_, or_, func`
- Use `from datetime import datetime, timedelta` for date math
- Use `datetime.utcnow()` consistently (matching existing codebase pattern)
- All methods return SQLAlchemy filter conditions (not query results)
- Add module docstring explaining this builds SQL WHERE clauses for pre-retrieval filtering
- Add type hints on all methods

**Do NOT:**
- Execute queries (this module only builds filter conditions)
- Import EmbeddingClient or do any embedding work
- Use raw SQL strings — use SQLAlchemy ORM operators only
  </action>
  <verify>
Run: `python -c "from execution.vector_db.metadata_filters import MetadataFilter, build_filters; print('Import OK')"` — should print "Import OK" without errors.

Run: `python -c "
from execution.vector_db.metadata_filters import MetadataFilter, build_filters
from datetime import datetime, timedelta
# Test date_range returns a clause
f = MetadataFilter.date_range(datetime(2025, 1, 1), datetime(2026, 1, 1))
print('date_range:', type(f).__name__)
# Test source_types
f2 = MetadataFilter.source_types(['email', 'rss'])
print('source_types:', type(f2).__name__)
# Test topic_tags
f3 = MetadataFilter.topic_tags(['ai', 'ml'])
print('topic_tags:', type(f3).__name__)
# Test build_filters
filters = build_filters('default', source_types=['email'])
print('build_filters returned', len(filters), 'conditions')
print('All filter tests passed')
"` — all prints should succeed.
  </verify>
  <done>MetadataFilter class with 5 static methods (date_range, source_types, topic_tags, recency, entities) and build_filters() convenience function. All return SQLAlchemy filter conditions. Importable without database connection.</done>
</task>

<task type="auto">
  <name>Task 2: Recency Scoring with Time Decay</name>
  <files>execution/vector_db/recency_scoring.py</files>
  <action>
Create `execution/vector_db/recency_scoring.py` with a `RecencyScorer` class implementing exponential half-life decay for trend-sensitive retrieval.

**RecencyScorer class:**

1. `__init__(self, half_life_days: int = 14)` — Store half-life parameter. Default 14 days per research recommendation.

2. `time_decay(self, date_published: Optional[datetime]) -> float` — Calculate decay factor using formula: `0.5 ^ (age_days / half_life_days)`. Returns float between 0 and 1. Handle None date_published (return 0.5 neutral). Handle future dates (clamp age_days to 0). Use `datetime.utcnow()`.

3. `is_trend_query(self, query: str) -> bool` — Detect trend-sensitive queries via keyword heuristics. Check if query contains any of: "latest", "recent", "new", "breaking", "current", "today", "2026", "now", "upcoming", "emerging", "trending". Case-insensitive word matching. Also detect year patterns like "202\d" via regex.

4. `apply_recency_boost(self, results: List[Dict], semantic_weight: float = 0.7, recency_weight: float = 0.3) -> List[Dict]` — For each result dict, compute `recency_score` from `date_published` key, then compute `fused_score = semantic_weight * rrf_score + recency_weight * recency_score`. Add both `recency_score` and `fused_score` keys to each result dict. Re-sort by `fused_score` descending. Handle missing `rrf_score` key (default to 0.5). Handle missing `date_published` key (neutral 0.5 recency).

5. `score_results(self, query: str, results: List[Dict], semantic_weight: float = 0.7, recency_weight: float = 0.3) -> List[Dict]` — Convenience method: if `is_trend_query(query)`, apply recency boost. Otherwise return results unchanged (no re-sorting). This is the main entry point for the retrieval orchestrator.

**Constants:**
- `TREND_KEYWORDS: Set[str]` — the trend keyword set (module-level frozen set)
- `DEFAULT_HALF_LIFE_DAYS: int = 14`

**Important:**
- Use `import math` for `math.pow(0.5, ...)`
- No database imports needed — this module operates on result dicts only
- Results are List[Dict] where each dict has at minimum "rrf_score" and optionally "date_published" (datetime or None)
- Add comprehensive docstrings with formula explanations
  </action>
  <verify>
Run: `python -c "
from execution.vector_db.recency_scoring import RecencyScorer
from datetime import datetime, timedelta

scorer = RecencyScorer(half_life_days=14)

# Test time_decay
today_score = scorer.time_decay(datetime.utcnow())
print(f'Today: {today_score:.4f}')  # Should be ~1.0
old_score = scorer.time_decay(datetime.utcnow() - timedelta(days=14))
print(f'14 days ago: {old_score:.4f}')  # Should be ~0.5
none_score = scorer.time_decay(None)
print(f'None date: {none_score:.4f}')  # Should be 0.5

# Test trend detection
assert scorer.is_trend_query('latest AI news') == True
assert scorer.is_trend_query('database architecture patterns') == False
print('Trend detection: OK')

# Test recency boost
results = [
    {'rrf_score': 0.9, 'date_published': datetime.utcnow() - timedelta(days=30)},
    {'rrf_score': 0.7, 'date_published': datetime.utcnow() - timedelta(days=1)},
]
boosted = scorer.apply_recency_boost(results)
print(f'Boosted order: fused_scores = {[r[\"fused_score\"]:.4f for r in boosted]}')
# Recent doc (0.7 semantic) should potentially beat old doc (0.9 semantic) after boost
print('All recency tests passed')
"` — all prints succeed, scores are reasonable.
  </verify>
  <done>RecencyScorer class with time_decay (half-life exponential), trend query detection, and recency boost application. Operates on result dicts without database dependency. Default 14-day half-life.</done>
</task>

<task type="auto">
  <name>Task 3: Citation Extraction</name>
  <files>execution/vector_db/citations.py</files>
  <action>
Create `execution/vector_db/citations.py` with a `CitationExtractor` class and `Citation` dataclass for sentence-level source attribution.

**Citation dataclass:**
```python
@dataclass
class Citation:
    text: str              # The sentence text
    citation_id: str       # Format: "{chunk_id}.{sentence_idx}" e.g. "42.3"
    chunk_id: int          # Parent chunk ID
    sentence_idx: int      # Sentence index within chunk
    title: Optional[str]   # Document title
    url: Optional[str]     # Document URL
    source_type: Optional[str]  # email, rss, paper
    date_published: Optional[datetime]  # Document date
```

**CitationExtractor class:**

1. `__init__(self)` — Create pysbd.Segmenter(language="en", clean=False). Reuse the same pattern as chunking.py (module-level segmenter for efficiency).

2. `extract_citations(self, chunk: Dict) -> List[Citation]` — Split chunk["content"] into sentences using pysbd. Create a Citation for each sentence. Expects chunk dict with keys: "id" (int), "content" (str), and optionally "title", "url", "source_type", "date_published". Citation ID format: `"{chunk_id}.{sentence_idx}"` where sentence_idx is 0-based.

3. `extract_from_results(self, results: List[Dict]) -> List[Citation]` — Convenience: call extract_citations for each result, return flat list of all citations. Preserves ordering (chunk order, then sentence order within chunk).

4. `format_citation_markdown(self, citation: Citation) -> str` — Format as `[Title](URL)`. If title is None, use "Source". If URL is None, use "#".

5. `format_context_block(self, citations: List[Citation]) -> str` — Build a context block for LLM prompts. Format each citation as `[{citation_id}] {text}` separated by newlines. This is what gets injected into RAG prompts so the LLM can reference specific citation IDs.

6. `build_citation_map(self, citations: List[Citation]) -> Dict[str, Citation]` — Create lookup dict from citation_id to Citation object. Used for resolving citation references in LLM output back to source metadata.

**Important:**
- Use the same pysbd pattern as chunking.py (already a project dependency)
- `from dataclasses import dataclass` for Citation
- `from typing import List, Dict, Optional`
- `from datetime import datetime`
- Module-level `_segmenter = pysbd.Segmenter(language="en", clean=False)` for reuse
- Handle empty content gracefully (return empty list)
- Handle chunks with no sentences (single-word content etc.)
  </action>
  <verify>
Run: `python -c "
from execution.vector_db.citations import CitationExtractor, Citation

extractor = CitationExtractor()

# Test extraction
chunk = {
    'id': 42,
    'content': 'PostgreSQL handles vector indexing well. The HNSW algorithm is fast. Cosine distance is used for similarity.',
    'title': 'pgvector Guide',
    'url': 'https://example.com/pgvector',
    'source_type': 'rss',
}
citations = extractor.extract_citations(chunk)
print(f'Extracted {len(citations)} citations from chunk')
for c in citations:
    print(f'  [{c.citation_id}] {c.text[:50]}...')

# Test markdown formatting
md = extractor.format_citation_markdown(citations[0])
print(f'Markdown: {md}')

# Test context block
block = extractor.format_context_block(citations)
print(f'Context block lines: {len(block.strip().splitlines())}')

# Test citation map
cmap = extractor.build_citation_map(citations)
assert '42.0' in cmap
assert '42.1' in cmap
print(f'Citation map has {len(cmap)} entries')

print('All citation tests passed')
"` — all prints succeed, 3 sentences extracted, markdown formatted, map built.
  </verify>
  <done>CitationExtractor with sentence-level citation extraction, markdown formatting, LLM context block builder, and citation map for resolving references. Uses pysbd (existing dependency). Citation dataclass with chunk_id.sentence_idx ID format.</done>
</task>

</tasks>

<verification>
All three modules import successfully without database connection:
```bash
python -c "from execution.vector_db.metadata_filters import MetadataFilter, build_filters; print('OK')"
python -c "from execution.vector_db.recency_scoring import RecencyScorer; print('OK')"
python -c "from execution.vector_db.citations import CitationExtractor, Citation; print('OK')"
```

Existing integration test still passes (these modules add new files, do not modify existing ones):
```bash
python -c "from execution.vector_db.indexing import semantic_search; print('semantic_search still importable')"
```
</verification>

<success_criteria>
1. MetadataFilter builds SQLAlchemy conditions for date_range, source_types, topic_tags, recency, and entities
2. build_filters() convenience function composes multiple filters with tenant_id
3. RecencyScorer.time_decay returns ~1.0 for today, ~0.5 for half_life_days ago
4. RecencyScorer.is_trend_query detects trend keywords correctly
5. CitationExtractor splits chunks into sentences with unique citation IDs
6. Citation dataclass provides structured metadata per sentence
7. All three modules are pure utility — no database queries, no side effects on import
8. Existing Phase 1 code unmodified and still importable
</success_criteria>

<output>
After completion, create `.planning/phases/02-retrieval-tools/02-01-SUMMARY.md`
</output>
